{
  "hash": "08b81d0de236224c01d1f5a8ea63fd53",
  "result": {
    "markdown": "---\ntitle: Biarchetype analysis\nsubtitle: Simultaneous learning of samples and features based on extremes\nauthor: Aleix Alcacer\ndate: '2022-11-16'\ncategories:\n  - archetypal analysis\n  - code\nbibliography: references.bib\nnocite: |\n  @*\nformat:\n  html:\n    code-fold: true\n---\n\n\\DeclareMathOperator*{\\argmin}{arg\\,min\\,}\n\\DeclareMathOperator*{\\argmax}{arg\\,max\\,}\n\n## Introduction\n\nArchetypal analysis was introduced by @Cutler1994. Let $X$ be a (real-valued) data matrix where the rows represent the samples of the data and the columns, the features. They defined the archetypes as convex combinations of the data samples, i.e. $Z = BX$ where $B$ is a stochastic matrix. In addition, the data samples are approximated by convex combinations of the archetypes, i.e. $X \\simeq AZ$ where $A$ and is also stochastic matrix. This is equivalent to solve the following optimization problem:\n\n$$\n\\begin{aligned}\n\\argmin_{A,B} \\quad &  \\|X - ABX \\|^2 \\\\\n\\textrm{s.t.} \\quad &  \\\\\n    & \\sum\\nolimits_{k=1}^K A_{mk} = 1 \\text{ with } A_{mk} \\in [0, 1] \\text{ for each } m=1,\\dots, M \\\\\n    & \\sum\\nolimits_{m=1}^M B_{km} = 1 \\text{ with } B_{km} \\in [0, 1] \\text{ for each } k=1,\\dots, K \\\\\n\\end{aligned}\n$${#eq-aa}\n\n\nTODO: Interpretation\n\n## BiArchetype Analysis\n\nIn BiAA, the archetypes are assumed to be convex combinations of the data in both dimensions, i.e. $Z = BXC$ where $B$ and $C$ are stochastic matrices. At the same time, the data is approximated by convex combinations of the archetypes, i.e. $X \\simeq AZD$ where $A$ and $D$ are also stochastic matrices.\n\nThis is equivalent to solve the following optimization problem:\n\n$$\n\\begin{aligned}\n\\argmin_{A,B,C,D} \\quad &  \\ell(X|ABXCD) \\\\\n\\textrm{s.t.} \\quad &  \\\\\n    & \\ell(X | \\tilde{X}) \\text{ should be a loss function} \\\\\n    & \\sum\\nolimits_{k=1}^K A_{mk} = 1 \\text{ with } A_{mk} \\in [0, 1] \\text{ for each } m=1,\\dots, M \\\\\n    & \\sum\\nolimits_{m=1}^M B_{km} = 1 \\text{ with } B_{km} \\in [0, 1] \\text{ for each } k=1,\\dots, K \\\\\n    & \\sum\\nolimits_{n=1}^N C_{nl} = 1 \\text{ with } D_{nl} \\in [0, 1] \\text{ for each } l=1,\\dots, L \\\\\n    & \\sum\\nolimits_{l=1}^L D_{ln} = 1 \\text{ with } D_{ln} \\in [0, 1] \\text{ for each } n=1,\\dots, N \\\\\n\\end{aligned}\n$${#eq-biaa}\n\n\nIn @eq-biaa, just as @Seth2016 proposed for archetypal analysis, $\\ell$ could be a negative log-likelihood function. Therefore,\n\n* for Bernoulli distributions $\\ell$ is defined as\n$$\n\\ell(X | \\tilde{X}) = -\\sum_{m=1}^M \\sum_{n=1}^N X_{mn}\\ln (\\tilde{X}_{mn}) + (1 - X_{mn}) \\ln (1 - \\tilde{X}_{mn})\n$${#eq-bernoulli-likelihood}\n\n* and for normal distributions,\n$$\n\\ell(X | \\tilde{X}) = MN \\ln \\left(\\sigma {\\sqrt {2\\pi }}\\right) + {\\frac {1}{2\\sigma^2}}\\sum_{m=1}^M \\sum_{n=1}^N \\left( {X_{mn}-\\tilde{X}_{mn} }\\right)^{2}\n$${#eq-normal-likelihood}\n\n\n## Example\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Temperature and ozone level.](index_files/figure-html/fig-airquality-output-1.png){#fig-airquality width=450 height=439}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}