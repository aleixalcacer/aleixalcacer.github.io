<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Aleix Alcacer</title>
<link>https://aleixalcacer.com/posts/index.html</link>
<atom:link href="https://aleixalcacer.com/posts/index.xml" rel="self" type="application/rss+xml"/>
<description>A great sample blog</description>
<generator>quarto-1.3.361</generator>
<lastBuildDate>Wed, 24 May 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Unleashing the Potential of the Flipped Classroom: Improving Class Attendance and Final Grades in Statistics Applied to Public Management and Administration</title>
  <link>https://aleixalcacer.com/posts/2023-05-25_iceri2023/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>TODO</p>
</section>
<section id="methods" class="level1">
<h1>Methods</h1>
<p>TODO</p>
</section>
<section id="results-and-discussion" class="level1">
<h1>Results and discussion</h1>
<p>TODO</p>
</section>
<section id="conclusions-and-future-work" class="level1">
<h1>Conclusions and future work</h1>
<p>TODO</p>
<div style="page-break-after: always;"></div>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2">
<div id="ref-bishop2013flipped" class="csl-entry">
Bishop, J., &amp; Verleger, M. A. (2013). The flipped classroom: A survey of the research. <em>2013 ASEE Annual Conference &amp; Exposition</em>, 23–1200.
</div>
</div>


</section>

 ]]></description>
  <category>flipped-classroom</category>
  <category>innovative teaching</category>
  <guid>https://aleixalcacer.com/posts/2023-05-25_iceri2023/index.html</guid>
  <pubDate>Wed, 24 May 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Biarchetype analysis</title>
  <link>https://aleixalcacer.com/posts/2022-06-11_archetypal-analysis/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Archetypal analysis was introduced by <span class="citation" data-cites="Cutler1994">Cutler &amp; Breiman (1994)</span>. Let <img src="https://latex.codecogs.com/png.latex?X"> be a (real-valued) data matrix where the rows represent the samples of the data and the columns, the features. They defined the archetypes as convex combinations of the data samples, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?Z%20=%20BX"> where <img src="https://latex.codecogs.com/png.latex?B"> is a stochastic matrix. In addition, the data samples are approximated by convex combinations of the archetypes, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?X%20%5Csimeq%20AZ"> where <img src="https://latex.codecogs.com/png.latex?A"> and is also stochastic matrix. This is equivalent to solve the following optimization problem:</p>
<p><span id="eq-aa"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cmathop%7B%5Cmathrm%7Barg%5C,min%5C,%7D%7D_%7BA,B%7D%20%5Cquad%20&amp;%20%20%5C%7CX%20-%20ABX%20%5C%7C%5E2%20%5C%5C%0A%5Ctextrm%7Bs.t.%7D%20%5Cquad%20&amp;%20%20%5C%5C%0A%20%20%20%20&amp;%20%5Csum%5Cnolimits_%7Bk=1%7D%5EK%20A_%7Bmk%7D%20=%201%20%5Ctext%7B%20with%20%7D%20A_%7Bmk%7D%20%5Cin%20%5B0,%201%5D%20%5Ctext%7B%20for%20each%20%7D%20m=1,%5Cdots,%20M%20%5C%5C%0A%20%20%20%20&amp;%20%5Csum%5Cnolimits_%7Bm=1%7D%5EM%20B_%7Bkm%7D%20=%201%20%5Ctext%7B%20with%20%7D%20B_%7Bkm%7D%20%5Cin%20%5B0,%201%5D%20%5Ctext%7B%20for%20each%20%7D%20k=1,%5Cdots,%20K%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Ctag%7B1%7D"></span></p>
<p>TODO: Interpretation</p>
</section>
<section id="biarchetype-analysis" class="level1">
<h1>BiArchetype Analysis</h1>
<p>In BiAA, the archetypes are assumed to be convex combinations of the data in both dimensions, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?Z%20=%20BXC"> where <img src="https://latex.codecogs.com/png.latex?B"> and <img src="https://latex.codecogs.com/png.latex?C"> are stochastic matrices. At the same time, the data is approximated by convex combinations of the archetypes, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?X%20%5Csimeq%20AZD"> where <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?D"> are also stochastic matrices.</p>
<p>This is equivalent to solve the following optimization problem:</p>
<p><span id="eq-biaa"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cmathop%7B%5Cmathrm%7Barg%5C,min%5C,%7D%7D_%7BA,B,C,D%7D%20%5Cquad%20&amp;%20%20%5Cell(X%7CABXCD)%20%5C%5C%0A%5Ctextrm%7Bs.t.%7D%20%5Cquad%20&amp;%20%20%5C%5C%0A%20%20%20%20&amp;%20%5Cell(X%20%7C%20%5Ctilde%7BX%7D)%20%5Ctext%7B%20should%20be%20a%20loss%20function%7D%20%5C%5C%0A%20%20%20%20&amp;%20%5Csum%5Cnolimits_%7Bk=1%7D%5EK%20A_%7Bmk%7D%20=%201%20%5Ctext%7B%20with%20%7D%20A_%7Bmk%7D%20%5Cin%20%5B0,%201%5D%20%5Ctext%7B%20for%20each%20%7D%20m=1,%5Cdots,%20M%20%5C%5C%0A%20%20%20%20&amp;%20%5Csum%5Cnolimits_%7Bm=1%7D%5EM%20B_%7Bkm%7D%20=%201%20%5Ctext%7B%20with%20%7D%20B_%7Bkm%7D%20%5Cin%20%5B0,%201%5D%20%5Ctext%7B%20for%20each%20%7D%20k=1,%5Cdots,%20K%20%5C%5C%0A%20%20%20%20&amp;%20%5Csum%5Cnolimits_%7Bn=1%7D%5EN%20C_%7Bnl%7D%20=%201%20%5Ctext%7B%20with%20%7D%20D_%7Bnl%7D%20%5Cin%20%5B0,%201%5D%20%5Ctext%7B%20for%20each%20%7D%20l=1,%5Cdots,%20L%20%5C%5C%0A%20%20%20%20&amp;%20%5Csum%5Cnolimits_%7Bl=1%7D%5EL%20D_%7Bln%7D%20=%201%20%5Ctext%7B%20with%20%7D%20D_%7Bln%7D%20%5Cin%20%5B0,%201%5D%20%5Ctext%7B%20for%20each%20%7D%20n=1,%5Cdots,%20N%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Ctag%7B2%7D"></span></p>
<p>In Equation&nbsp;2, just as <span class="citation" data-cites="Seth2016">Seth &amp; Eugster (2016)</span> proposed for archetypal analysis, <img src="https://latex.codecogs.com/png.latex?%5Cell"> could be a negative log-likelihood function. Therefore,</p>
<ul>
<li><p>for Bernoulli distributions <img src="https://latex.codecogs.com/png.latex?%5Cell"> is defined as <span id="eq-bernoulli-likelihood"><img src="https://latex.codecogs.com/png.latex?%0A%5Cell(X%20%7C%20%5Ctilde%7BX%7D)%20=%20-%5Csum_%7Bm=1%7D%5EM%20%5Csum_%7Bn=1%7D%5EN%20X_%7Bmn%7D%5Cln%20(%5Ctilde%7BX%7D_%7Bmn%7D)%20+%20(1%20-%20X_%7Bmn%7D)%20%5Cln%20(1%20-%20%5Ctilde%7BX%7D_%7Bmn%7D)%0A%5Ctag%7B3%7D"></span></p></li>
<li><p>and for normal distributions, <span id="eq-normal-likelihood"><img src="https://latex.codecogs.com/png.latex?%0A%5Cell(X%20%7C%20%5Ctilde%7BX%7D)%20=%20MN%20%5Cln%20%5Cleft(%5Csigma%20%7B%5Csqrt%20%7B2%5Cpi%20%7D%7D%5Cright)%20+%20%7B%5Cfrac%20%7B1%7D%7B2%5Csigma%5E2%7D%7D%5Csum_%7Bm=1%7D%5EM%20%5Csum_%7Bn=1%7D%5EN%20%5Cleft(%20%7BX_%7Bmn%7D-%5Ctilde%7BX%7D_%7Bmn%7D%20%7D%5Cright)%5E%7B2%7D%0A%5Ctag%7B4%7D"></span></p></li>
</ul>
</section>
<section id="example" class="level1">
<h1>Example</h1>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"></span>
<span id="cb1-4">r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>)</span>
<span id="cb1-5">theta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.pi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> r</span>
<span id="cb1-6">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(</span>
<span id="cb1-7">  subplot_kw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'projection'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'polar'</span>} </span>
<span id="cb1-8">)</span>
<span id="cb1-9">ax.plot(theta, r)</span>
<span id="cb1-10">ax.set_rticks([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb1-11">ax.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb1-12">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-airquality" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://aleixalcacer.com/posts/2022-06-11_archetypal-analysis/index_files/figure-html/fig-airquality-output-1.png" width="450" height="439" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Temperature and ozone level.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2">
<div id="ref-Cutler1994" class="csl-entry">
Cutler, A., &amp; Breiman, L. (1994). Archetypal analysis. <em>Technometrics</em>, <em>36</em>, 338–347. <a href="https://doi.org/10.1080/00401706.1994.10485840">https://doi.org/10.1080/00401706.1994.10485840</a>
</div>
<div id="ref-Morup2012" class="csl-entry">
Mørup, M., &amp; Hansen, L. K. (2012). Archetypal analysis for machine learning and data mining. <em>Neurocomputing</em>, <em>80</em>, 54–63. <a href="https://doi.org/10.1016/j.neucom.2011.06.033">https://doi.org/10.1016/j.neucom.2011.06.033</a>
</div>
<div id="ref-Seth2016" class="csl-entry">
Seth, S., &amp; Eugster, M. J. A. (2016). Probabilistic archetypal analysis. <em>Machine Learning</em>, <em>102</em>, 85–113. <a href="https://doi.org/10.1007/S10994-015-5498-8/FIGURES/14">https://doi.org/10.1007/S10994-015-5498-8/FIGURES/14</a>
</div>
</div>


</section>

 ]]></description>
  <category>archetypal analysis</category>
  <category>matrix factorization</category>
  <guid>https://aleixalcacer.com/posts/2022-06-11_archetypal-analysis/index.html</guid>
  <pubDate>Wed, 16 Nov 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Bridging Archetypal Analysis and Stochastic Block Models</title>
  <link>https://aleixalcacer.com/posts/2022-12-01_biaa-sbm/index.html</link>
  <description><![CDATA[ 



<p><img src="https://latex.codecogs.com/png.latex?%0A%5CDeclareMathOperator*%7B%5Cargmin%7D%7Barg%5C,min%7D%0A%5CDeclareMathOperator*%7B%5Cargmax%7D%7Barg%5C,max%7D%0A"></p>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Research Questions:</p>
<ul>
<li>BiAA as a bridge between AA and SBM.</li>
<li>BiAA extensions:
<ul>
<li>Multiple likelihoods (Normal, Bernoulli, Poisson)</li>
<li>Hard assignment</li>
<li>Degree correction</li>
</ul></li>
<li>What are the merits of Bi-AA as opposed to SBM?
<ul>
<li>Soft clustering</li>
<li>Better interpretation</li>
</ul></li>
</ul>
<p>This research paper presents an extension of the Biarchetype Analysis (BiAA) method for bridging Archetypal Analysis and Stochastic Block Models analysis. The proposed extension includes the support of multiple likelihood functions (Normal, Bernoulli and Poisson), the use of a hard assignment mode, and the application of degree correction. The paper also compares the merits of BiAA to existing stochastic block model (SBM) algorithms, with a focus on the benefits of soft clustering and better interpretation of the results.</p>
<p>Biarchetype analysis is a statistical method that aims to uncover the underlying structure of data by grouping similar observations into clusters or archetypes. As it is said, the proposed extension of BiAA includes the incorporation of multiple likelihood functions, which allows for the use of different probability distributions to model the data. This enables the method to be applied to a wider range of data types, such as binary data, count data, and continuous data.</p>
<p>In addition, the proposed extension includes the use of a hard assignment mode, which assigns each observation to the archetype with the highest probability of membership. This allows for a more straightforward interpretation of the results, compared to the soft assignment mode used in the original BiAA method, where each observation is assigned a probability of membership in each archetype.</p>
<p>Finally, a degree correction is incorporated to BiAA, which adjusts the weights assigned to the nodes in the network based on their degree (i.e., the number of connections they have to other nodes). This ensures that nodes with higher degrees are not given too much influence in the calculation of the archetypes, which can lead to more accurate and unbiased results.</p>
<p>The paper also compares the merits of BiAA to existing SBM algorithms, which are commonly used for detecting community structure in networks. One key advantage of BiAA is its ability to perform soft clustering, where each observation can belong to multiple archetypes with varying degrees of membership. This allows for a more nuanced representation of the data and the underlying structure of the network. In contrast, SBM algorithms typically perform hard clustering, where each observation is assigned to exactly one block or community.</p>
<p>Another advantage of BiAA is its ability to provide better interpretation of the results. The archetypes identified by BiAA are derived from the data itself, and can be interpreted as extreme points in the data space. This allows for a more intuitive understanding of the patterns and structures in the data, compared to the block assignments produced by SBM algorithms, which are based on the probabilities of connections between nodes in the network.</p>
<p>Overall, the proposed extension of BiAA offers a bridge between archetypal analysis and SBM analysis, providing a different framework for community structure detection analysis. Therefore, BiAA will be an alternative and valuable tool for uncovering the underlying structure of communities and gaining insights into the patterns and structures present in the data.</p>
</section>
<section id="methods" class="level1">
<h1>Methods</h1>
<section id="likelihood-functions" class="level2">
<h2 class="anchored" data-anchor-id="likelihood-functions">Likelihood functions</h2>
<p>Likelihood functions are used in statistical modeling to evaluate the quality of a model’s predictions. They are a measure of how well a model fits the observed data. By maximizing the likelihood of the model, it is possible to improve the model’s accuracy and make better predictions.</p>
<p>In the article, log-likelihood functions will be used as error functions in the defined models. This means that the models will be trained to minimize the negative log-likelihood of their predictions, which will improve their accuracy. The Normal, Bernoulli, and Poisson log-likelihood functions will be used in this case, which are appropriate for models that make predictions using normal, binary, and count data, respectively.</p>
<section id="normal-distribution" class="level3">
<h3 class="anchored" data-anchor-id="normal-distribution">Normal distribution</h3>
<p>The normal log-likelihood function is used to calculate the log-likelihood of a normal distribution given a set of data. The formula for the normal log-likelihood function is as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?log(L)%20=%20-%5Cfrac%7Bn%7D%7B2%7D%20log(2%20%5Cpi)%20-%20%5Cfrac%7Bn%7D%7B2%7D%20log(%5Csigma%5E2)%20-%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%5Cfrac%7B(x_i%20-%20%5Cmu)%5E2%7D%7B2%20%5Csigma%5E2%7D"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?L"> is the likelihood function, <img src="https://latex.codecogs.com/png.latex?n"> is the number of data points, <img src="https://latex.codecogs.com/png.latex?x_i"> is the <img src="https://latex.codecogs.com/png.latex?i">-th data point, <img src="https://latex.codecogs.com/png.latex?%5Cmu"> is the mean of the data, <img src="https://latex.codecogs.com/png.latex?%5Csigma"> is the standard deviation of the data, and the summation is over all data points in the sample.</p>
</section>
<section id="bernoulli-distribution" class="level3">
<h3 class="anchored" data-anchor-id="bernoulli-distribution">Bernoulli distribution</h3>
<p>The Bernoulli log-likelihood function is used to calculate the log-likelihood of a Bernoulli distribution given a set of data. The formula for the Bernoulli log-likelihood function is as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?log(L)%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%5By_i%20%5Ccdot%20log(p)%20+%20(1%20-%20y_i)%20%5Ccdot%20log(1%20-%20p)%5D"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?L"> is the likelihood function, <img src="https://latex.codecogs.com/png.latex?y_i"> is the outcome of the binary event (1 if the event happened, 0 if it did not), <img src="https://latex.codecogs.com/png.latex?p"> is the probability of the event happening, and the summation is over all events in the data.</p>
</section>
<section id="poisson-distribution" class="level3">
<h3 class="anchored" data-anchor-id="poisson-distribution">Poisson distribution</h3>
<p>Finally, the Poisson log-likelihood function is used to calculate the log-likelihood of a Poisson distribution given a set of data. The formula for the Poisson log-likelihood function is as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?log(L)%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%5Bn_i%20%5Ccdot%20log(%5Clambda)%20-%20%5Clambda%20-%20log(n_i!)%5D"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?L"> is the likelihood function, <img src="https://latex.codecogs.com/png.latex?n_i"> is the number of events observed in the <img src="https://latex.codecogs.com/png.latex?i">-th group, <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is the rate parameter of the Poisson distribution, and the summation is over all groups in the data.</p>
</section>
</section>
<section id="stochastic-block-model" class="level2">
<h2 class="anchored" data-anchor-id="stochastic-block-model">Stochastic Block Model</h2>
<p>The Stochastic Block Model (SBM) is a popular model used to generate synthetic networks with community structure. In an SBM, the nodes in the network are divided into groups or “blocks”, and the connections between nodes are determined by the blocks they belong to. The SBM is often used to test the performance of community detection algorithms, which are algorithms that aim to identify the groups or communities present in a network.</p>
<p>For bipartite networks, the SBM can be viewed as a matrix factorization problem where the adjacency matrix (which represents the connections between the nodes) is decomposed into three matrices, one representing the blocks and the others representing the connections between the blocks. More specifically, let <img src="https://latex.codecogs.com/png.latex?X"> be the adjacency matrix of a network with <img src="https://latex.codecogs.com/png.latex?M"> and <img src="https://latex.codecogs.com/png.latex?N"> nodes respectively, where <img src="https://latex.codecogs.com/png.latex?A_%7Bij%7D"> is the number of connections between nodes <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j">. In the SBM, this adjacency matrix can be written as the product of three matrices, <img src="https://latex.codecogs.com/png.latex?A">, <img src="https://latex.codecogs.com/png.latex?Z"> and <img src="https://latex.codecogs.com/png.latex?C">, where <img src="https://latex.codecogs.com/png.latex?A"> is a <img src="https://latex.codecogs.com/png.latex?M%5Ctimes%20K"> matrix, <img src="https://latex.codecogs.com/png.latex?Z"> is a <img src="https://latex.codecogs.com/png.latex?K%5Ctimes%20L"> matrix and <img src="https://latex.codecogs.com/png.latex?D"> is a <img src="https://latex.codecogs.com/png.latex?L%5Ctimes%20N"> matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?X%20%5Capprox%20AZD"></p>
<p>Here, <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?D"> are the matrices that represents the blocks, where <img src="https://latex.codecogs.com/png.latex?A_%7Bik%7D"> is the membership of node <img src="https://latex.codecogs.com/png.latex?i"> in block <img src="https://latex.codecogs.com/png.latex?k"> and <img src="https://latex.codecogs.com/png.latex?D_%7Blj%7D"> is the membership of node <img src="https://latex.codecogs.com/png.latex?j"> in block <img src="https://latex.codecogs.com/png.latex?l">. <img src="https://latex.codecogs.com/png.latex?Z"> is the matrix that represents the connections between the blocks, where <img src="https://latex.codecogs.com/png.latex?Z_%7Bkl%7D"> is the probability of a connection between nodes in block <img src="https://latex.codecogs.com/png.latex?k"> and block <img src="https://latex.codecogs.com/png.latex?l">.</p>
<p>The matrix factorization of the adjacency matrix in the SBM allows us to model the community structure of the network by defining the blocks and the connections between the blocks. The blocks can be thought of as the groups or communities in the network, and the connections between the blocks can be used to control the strength and structure of the communities. For example, if <img src="https://latex.codecogs.com/png.latex?Z_%7Bkl%7D"> is high, it indicates that there are many connections between nodes in block <img src="https://latex.codecogs.com/png.latex?k"> and block <img src="https://latex.codecogs.com/png.latex?l">, and the corresponding communities are likely to be strongly connected. On the other hand, if <img src="https://latex.codecogs.com/png.latex?Z_%7Bkl%7D"> is low, it indicates that there are few connections between nodes in block <img src="https://latex.codecogs.com/png.latex?k"> and block <img src="https://latex.codecogs.com/png.latex?l">, and the corresponding communities are likely to be weakly connected.</p>
<p>In summary, the Stochastic Block Model is a popular model for generating synthetic networks with community structure, and it can be viewed as a matrix factorization problem where the adjacency matrix of the network is decomposed into three matrices representing the blocks and the connections between the blocks.</p>
<p>References: .</p>
<pre><code># $$X_{MN} \sim A_{MK} Z_{KL} D_{LN}$$</code></pre>
</section>
<section id="biarchetype-analysis" class="level2">
<h2 class="anchored" data-anchor-id="biarchetype-analysis">Biarchetype Analysis</h2>
<p>[Archetype and biarchetype analysis definition]</p>
<p>Therfore, this method can be seen as a particular case of the Stochastic Block Model where the matrix <img src="https://latex.codecogs.com/png.latex?Z">, that represents the relationships between groups, is defined by taking convex combinations of the data <img src="https://latex.codecogs.com/png.latex?X">. This means that the matrix <img src="https://latex.codecogs.com/png.latex?Z">, called the archetypal matrix, is constructed as <img src="https://latex.codecogs.com/png.latex?Z%20=%20BXC"> where <img src="https://latex.codecogs.com/png.latex?X"> is the matrix representing the original data points and <img src="https://latex.codecogs.com/png.latex?B"> and <img src="https://latex.codecogs.com/png.latex?C"> are matrices that represent the coefficients of the convex combination. By defining the relationship matrix in this way, Biarchetype Analysis is able to interpret the matrix <img src="https://latex.codecogs.com/png.latex?Z"> based on input data.</p>
</section>
<section id="degree-correction" class="level2">
<h2 class="anchored" data-anchor-id="degree-correction">Degree correction</h2>
<p>A degree corrected algorithm is a variant of an existing algorithm that has been modified to account for the fact that the nodes in a network may have different degrees (i.e., different numbers of connections to other nodes). In many networks, the nodes have varying degrees, and a standard algorithm may not perform well when applied to such a network because it may give more weight to nodes with higher degrees, leading to biased or inaccurate results. A degree corrected algorithm addresses this issue by taking into account the degrees of the nodes when calculating the algorithm’s result.</p>
<p>For example, when applying a community detection algorithm to a network generated using the SBM, it is important to take into account the degree distribution of the nodes in the network. The degree distribution of a network is the distribution of the number of connections (or “edges”) that each node has to other nodes in the network. In a network generated using the SBM, the degree distribution of the nodes will be different depending on the blocks they belong to. For example, nodes in the same block will tend to have similar degrees, while nodes in different blocks will have different degrees.</p>
<p>If a standard community detection algorithm is applied to a network generated using the SBM, it may not perform well because it may give more weight to nodes with higher degrees, leading to biased or inaccurate results. A degree corrected version of the algorithm, on the other hand, would take into account the degree distribution of the nodes and give less weight to nodes with higher degrees, resulting in more accurate community detection.</p>
</section>
<section id="proposed-models" class="level2">
<h2 class="anchored" data-anchor-id="proposed-models">Proposed Models</h2>
<section id="soft-sbm" class="level3">
<h3 class="anchored" data-anchor-id="soft-sbm">Soft SBM</h3>
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bequation%7D%0A%20%20%20%20%5Cargmax_%7BA,%20Z,%20D%7D%20l(AZD;%20X)%0A%5Cend%7Bequation%7D"> such that:
</section>
<section id="hard-sbm" class="level3">
<h3 class="anchored" data-anchor-id="hard-sbm">Hard SBM</h3>
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bequation%7D%0A%20%20%20%20%5Cargmax_%7BA,%20Z,%20D%7D%20l(AZD;%20X)%0A%5Cend%7Bequation%7D"> such that:
</section>
</section>
<section id="biarchetype-analysis-1" class="level2">
<h2 class="anchored" data-anchor-id="biarchetype-analysis-1">BiArchetype Analysis</h2>
<p>References: </p>
<p>BiAA is a special case of SBM (<img src="https://latex.codecogs.com/png.latex?Z_%7BKL%7D%20=%20B_%7BKM%7D%20X_%7BMN%7D%20C_%7BNL%7D">).</p>
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bequation%7D%0A%20%20%20%20%5Cargmax_%7BA,%20B,%20C,%20D%7D%20l(ABXCD;%20X)%0A%5Cend%7Bequation%7D"> such that:
<section id="hard-assignment" class="level3">
<h3 class="anchored" data-anchor-id="hard-assignment">Hard assignment</h3>
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bequation%7D%0A%20%20%20%20%5Cargmax_%7BA,%20B,%20C,%20D%7D%20l(ABXCD;%20X)%0A%5Cend%7Bequation%7D"> such that:
<p>NOTE: The prototypes are not in the boundary of the CH. References: </p>
<p>Change restrictions 2, 3 such that</p>
</section>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<p>Normalized Mutual Information: </p>
<p>3 When Bernoulli likelihood is used for SBM synthetic graphs, the <img src="https://latex.codecogs.com/png.latex?Z"> matrix of the SBM and the <img src="https://latex.codecogs.com/png.latex?Z"> matrix (<img src="https://latex.codecogs.com/png.latex?Z=BXC">) of the BiAA are equal to the probabilities used to construct the graph.</p>
<section id="sbm-based-synthetic-data" class="level2">
<h2 class="anchored" data-anchor-id="sbm-based-synthetic-data">SBM-based synthetic data</h2>
</section>
<section id="biaa-based-synthetic-data" class="level2">
<h2 class="anchored" data-anchor-id="biaa-based-synthetic-data">BiAA-based synthetic data</h2>
</section>
<section id="real-datasets" class="level2">
<h2 class="anchored" data-anchor-id="real-datasets">Real datasets</h2>
<section id="restaurant-recommender-system" class="level3">
<h3 class="anchored" data-anchor-id="restaurant-recommender-system">Restaurant recommender system</h3>
<p> Source: </p>
</section>
<section id="drug-side-effect-association" class="level3">
<h3 class="anchored" data-anchor-id="drug-side-effect-association">Drug side-effect association</h3>
<p> Source: </p>
</section>
<section id="nips-author-collaboration" class="level3">
<h3 class="anchored" data-anchor-id="nips-author-collaboration">NIPS author collaboration</h3>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>


</section>
</section>

 ]]></description>
  <guid>https://aleixalcacer.com/posts/2022-12-01_biaa-sbm/index.html</guid>
  <pubDate>Mon, 19 Jun 2023 10:39:19 GMT</pubDate>
</item>
</channel>
</rss>
